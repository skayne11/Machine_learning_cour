{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/melb_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "810 fits failed out of a total of 2430.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "587 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "223 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [             nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan -174186.16687853\n",
      " -173005.02181882 -172771.54903558 -174290.3708157  -173698.02429545\n",
      " -173395.2902623  -176123.18174868 -175180.15270195 -174998.44536406\n",
      " -174268.97219747 -173574.69366474 -173345.2751064  -174353.45055465\n",
      " -173444.95973502 -173347.44646334 -176031.34022055 -175340.49244695\n",
      " -175277.92202155 -176850.79920677 -176060.66751335 -175976.04391639\n",
      " -176850.79920677 -176060.66751335 -175976.04391639 -177258.66464547\n",
      " -176459.68014534 -176383.9709262  -174186.16687853 -173005.02181882\n",
      " -172771.54903558 -174290.3708157  -173698.02429545 -173395.2902623\n",
      " -176123.18174868 -175180.15270195 -174998.44536406 -174268.97219747\n",
      " -173574.69366474 -173345.2751064  -174353.45055465 -173444.95973502\n",
      " -173347.44646334 -176031.34022055 -175340.49244695 -175277.92202155\n",
      " -176850.79920677 -176060.66751335 -175976.04391639 -176850.79920677\n",
      " -176060.66751335 -175976.04391639 -177258.66464547 -176459.68014534\n",
      " -176383.9709262               nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      " -193567.89568058 -193249.12784413 -193104.16601865 -194155.57821876\n",
      " -193464.00423913 -193313.27844916 -194047.59641694 -193668.46138108\n",
      " -193775.81526913 -193333.85187319 -192811.00533721 -192662.66734508\n",
      " -193363.725308   -193010.92155312 -192852.12448826 -194001.73146266\n",
      " -193496.28555046 -193388.53416293 -193273.03459745 -192846.84016276\n",
      " -192759.00889707 -193273.03459745 -192846.84016276 -192759.00889707\n",
      " -193878.89244427 -193300.95185756 -192969.6387076  -193567.89568058\n",
      " -193249.12784413 -193104.16601865 -194155.57821876 -193464.00423913\n",
      " -193313.27844916 -194047.59641694 -193668.46138108 -193775.81526913\n",
      " -193333.85187319 -192811.00533721 -192662.66734508 -193363.725308\n",
      " -193010.92155312 -192852.12448826 -194001.73146266 -193496.28555046\n",
      " -193388.53416293 -193273.03459745 -192846.84016276 -192759.00889707\n",
      " -193273.03459745 -192846.84016276 -192759.00889707 -193878.89244427\n",
      " -193300.95185756 -192969.6387076               nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan -174445.29432234 -173405.47908273 -173356.04790686\n",
      " -174958.91349978 -174097.48387959 -173757.13322275 -176421.33018889\n",
      " -175663.92680866 -175467.9686175  -174695.41420946 -173790.71557238\n",
      " -173501.99190915 -174703.21758277 -173885.53519328 -173809.3299864\n",
      " -176160.19115809 -175490.43976544 -175424.10470103 -176281.31156397\n",
      " -176057.36944843 -176003.93476569 -176281.31156397 -176057.36944843\n",
      " -176003.93476569 -177628.08627054 -176742.89701398 -176546.99980443\n",
      " -174445.29432234 -173405.47908273 -173356.04790686 -174958.91349978\n",
      " -174097.48387959 -173757.13322275 -176421.33018889 -175663.92680866\n",
      " -175467.9686175  -174695.41420946 -173790.71557238 -173501.99190915\n",
      " -174703.21758277 -173885.53519328 -173809.3299864  -176160.19115809\n",
      " -175490.43976544 -175424.10470103 -176281.31156397 -176057.36944843\n",
      " -176003.93476569 -176281.31156397 -176057.36944843 -176003.93476569\n",
      " -177628.08627054 -176742.89701398 -176546.99980443              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan -174843.72628277 -173887.75287662\n",
      " -173687.53082572 -173807.81477099 -173050.75754218 -172890.55902618\n",
      " -174042.30559153 -173488.44962051 -173248.699284   -173392.94030972\n",
      " -172423.77630806 -172324.04397537 -173323.39273654 -172649.01613528\n",
      " -172545.74799349 -173968.12781339 -173309.06473841 -173237.81666898\n",
      " -174105.59245739 -173665.7302663  -173528.09450693 -174105.59245739\n",
      " -173665.7302663  -173528.09450693 -174597.82024746 -174142.7999375\n",
      " -173958.00090631 -174843.72628277 -173887.75287662 -173687.53082572\n",
      " -173807.81477099 -173050.75754218 -172890.55902618 -174042.30559153\n",
      " -173488.44962051 -173248.699284   -173392.94030972 -172423.77630806\n",
      " -172324.04397537 -173323.39273654 -172649.01613528 -172545.74799349\n",
      " -173968.12781339 -173309.06473841 -173237.81666898 -174105.59245739\n",
      " -173665.7302663  -173528.09450693 -174105.59245739 -173665.7302663\n",
      " -173528.09450693 -174597.82024746 -174142.7999375  -173958.00090631\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan -193539.69876981\n",
      " -193293.7233489  -193181.94362902 -193511.34737337 -193279.88426826\n",
      " -193278.79016068 -193810.43988359 -193433.37327601 -193310.05162473\n",
      " -193425.71569316 -192836.31632478 -192738.99409747 -192921.57485738\n",
      " -192772.94403436 -192855.00596154 -193509.23233462 -193109.92737156\n",
      " -192966.48108044 -193302.92635773 -192829.08008181 -192763.12686441\n",
      " -193302.92635773 -192829.08008181 -192763.12686441 -193372.47942942\n",
      " -192999.37989204 -192803.86983379 -193539.69876981 -193293.7233489\n",
      " -193181.94362902 -193511.34737337 -193279.88426826 -193278.79016068\n",
      " -193810.43988359 -193433.37327601 -193310.05162473 -193425.71569316\n",
      " -192836.31632478 -192738.99409747 -192921.57485738 -192772.94403436\n",
      " -192855.00596154 -193509.23233462 -193109.92737156 -192966.48108044\n",
      " -193302.92635773 -192829.08008181 -192763.12686441 -193302.92635773\n",
      " -192829.08008181 -192763.12686441 -193372.47942942 -192999.37989204\n",
      " -192803.86983379              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      "              nan              nan              nan              nan\n",
      " -174792.65474448 -173881.06828443 -173578.04581153 -173882.60947824\n",
      " -173279.06657355 -173114.1774841  -173943.45213123 -173599.74127246\n",
      " -173546.91035661 -173545.89837924 -172720.56102293 -172568.18527661\n",
      " -173777.64359023 -172920.89446332 -172764.42083096 -173923.87228689\n",
      " -173602.8761753  -173441.31160029 -174143.56031539 -173831.34207601\n",
      " -173743.42223214 -174143.56031539 -173831.34207601 -173743.42223214\n",
      " -174569.46574756 -174285.39797617 -174065.50571953 -174792.65474448\n",
      " -173881.06828443 -173578.04581153 -173882.60947824 -173279.06657355\n",
      " -173114.1774841  -173943.45213123 -173599.74127246 -173546.91035661\n",
      " -173545.89837924 -172720.56102293 -172568.18527661 -173777.64359023\n",
      " -172920.89446332 -172764.42083096 -173923.87228689 -173602.8761753\n",
      " -173441.31160029 -174143.56031539 -173831.34207601 -173743.42223214\n",
      " -174143.56031539 -173831.34207601 -173743.42223214 -174569.46574756\n",
      " -174285.39797617 -174065.50571953]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best MAE (Negative): -172324.04\n",
      "Best MAE (Positive): 172324.04\n",
      "Final Mean Absolute Error on all data: 50556.86\n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "me_file_path = './dataset/melb_data.csv'\n",
    "me_data = pd.read_csv(me_file_path)\n",
    "\n",
    "# Imputation des valeurs manquantes\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "me_data[me_data.select_dtypes(include=[np.number]).columns] = imputer.fit_transform(me_data.select_dtypes(include=[np.number]))\n",
    "\n",
    "# Encoder les colonnes catégoriques via Target Encoding\n",
    "if 'Suburb' in me_data.columns:\n",
    "    suburb_mean_price = me_data.groupby('Suburb')['Price'].mean()\n",
    "    me_data['Suburb_encoded'] = me_data['Suburb'].map(suburb_mean_price)\n",
    "    me_data.drop(columns=['Suburb'], inplace=True)\n",
    "\n",
    "# Créer des caractéristiques supplémentaires\n",
    "me_data['Landsize_squared'] = me_data['Landsize'] ** 2\n",
    "me_data['BuildingArea_log'] = np.log1p(me_data['BuildingArea'])\n",
    "me_data['Rooms_Bathroom'] = me_data['Rooms'] * me_data['Bathroom']\n",
    "\n",
    "# Sélectionner les caractéristiques et la cible\n",
    "y = me_data['Price']\n",
    "fme_features = [\n",
    "    'Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt',\n",
    "    'Lattitude', 'Longtitude', 'Suburb_encoded',\n",
    "    'Landsize_squared', 'BuildingArea_log', 'Rooms_Bathroom'\n",
    "]\n",
    "X = me_data[fme_features]\n",
    "\n",
    "# Discrétiser la cible pour utiliser StratifiedKFold\n",
    "y_binned = pd.qcut(y, q=5, labels=False)  # Diviser les prix en 5 catégories\n",
    "\n",
    "# Initialiser StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paramètres pour GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Chaînes valides pour max_features\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Modèle Random Forest\n",
    "model = RandomForestRegressor(random_state=42, n_jobs=-1)  # Fixer les paramètres constants ici\n",
    "\n",
    "# GridSearchCV avec StratifiedKFold\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=skf.split(X_scaled, y_binned),  # Validation croisée stratifiée\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entraîner le modèle avec GridSearchCV\n",
    "grid_search.fit(X_train, y)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Meilleure performance (MAE)\n",
    "print(f\"Best MAE (Negative): {grid_search.best_score_:.2f}\")\n",
    "print(f\"Best MAE (Positive): {-grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Résultats finaux sur tout l'ensemble de données (optionnel)\n",
    "preds = best_model.predict(X_test)\n",
    "mae_final = mean_absolute_error(y, preds)\n",
    "print(f\"Final Mean Absolute Error on all data: {mae_final:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mean Absolute Error: 226925.9660191458\n"
     ]
    }
   ],
   "source": [
    "# Imputation des valeurs manquantes\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "me_data[me_data.select_dtypes(include=[np.number]).columns] = imputer.fit_transform(me_data.select_dtypes(include=[np.number]))\n",
    "\n",
    "# Encoder les colonnes catégoriques via Target Encoding\n",
    "if 'Suburb' in me_data.columns:\n",
    "    suburb_mean_price = me_data.groupby('Suburb')['Price'].mean()\n",
    "    me_data['Suburb_encoded'] = me_data['Suburb'].map(suburb_mean_price)\n",
    "    me_data.drop(columns=['Suburb'], inplace=True)\n",
    "\n",
    "# Créer des caractéristiques supplémentaires\n",
    "me_data['Landsize_squared'] = me_data['Landsize'] ** 2\n",
    "me_data['BuildingArea_log'] = np.log1p(me_data['BuildingArea'])\n",
    "me_data['Rooms_Bathroom'] = me_data['Rooms'] * me_data['Bathroom']\n",
    "\n",
    "# Sélectionner les caractéristiques importantes et la cible\n",
    "y = me_data['Price']\n",
    "fme_features = [\n",
    "    'Suburb_encoded', 'Rooms', 'Longtitude', 'Lattitude', \n",
    "    'Landsize_squared', 'Landsize', 'Rooms_Bathroom',\n",
    "    'YearBuilt', 'BuildingArea_log', 'BuildingArea', 'Bathroom', 'Postcode', 'Bedroom2', 'Distance'\n",
    "]\n",
    "\n",
    "X = me_data[fme_features]\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraîner le modèle avec les meilleurs paramètres\n",
    "best_params = {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 1000}\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    bootstrap= False,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions et évaluation\n",
    "preds = model.predict(X_test)\n",
    "mae_final = mean_absolute_error(y_test, preds)\n",
    "print(\"Final Mean Absolute Error:\", mae_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
