{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Skayne\\Desktop\\cours_tech\\Machine learning\\env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 16s/step\n",
      "Exactitude du modèle XGBoost: 0.89\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Charger un modèle pré-entraîné (par ex. VGG16)\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# 2. Préparer les images avec ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Indiquer le répertoire des images\n",
    "train_data = datagen.flow_from_directory(\n",
    "    './dataset/car_or_truck/train',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=128,\n",
    "    class_mode='binary',  # 'categorical' pour plusieurs classes\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 3. Extraire les caractéristiques avec VGG16\n",
    "def extract_features(model, data):\n",
    "    features = model.predict(data)\n",
    "    return features.reshape(features.shape[0], -1)  # Aplatir les caractéristiques\n",
    "\n",
    "# Extraire les caractéristiques des images\n",
    "features = extract_features(vgg_model, train_data)\n",
    "\n",
    "# Obtenir les étiquettes\n",
    "labels = train_data.classes\n",
    "\n",
    "# 4. Diviser les données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Entraîner XGBoost pour la classification en utilisant le GPU\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Évaluer le modèle sur l'ensemble de test\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Exactitude du modèle XGBoost: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 images belonging to 2 classes.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 4s/step\n",
      "Exactitude du modèle XGBoost: 0.87\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19  # Remplacer VGG16 par VGG19\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Charger un modèle pré-entraîné (par ex. VGG19)\n",
    "vgg_model = VGG19(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# 2. Préparer les images avec ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Indiquer le répertoire des images\n",
    "train_data = datagen.flow_from_directory(\n",
    "    './dataset/car_or_truck/train',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=128,\n",
    "    class_mode='binary',  # 'categorical' pour plusieurs classes\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 3. Extraire les caractéristiques avec VGG19\n",
    "def extract_features(model, data):\n",
    "    # Extraire les caractéristiques en prédiction\n",
    "    features = model.predict(data)\n",
    "    return features.reshape(features.shape[0], -1)  # Aplatir les caractéristiques pour XGBoost\n",
    "\n",
    "# Extraire les caractéristiques des images d'entraînement\n",
    "features = extract_features(vgg_model, train_data)\n",
    "\n",
    "# Obtenir les étiquettes\n",
    "labels = train_data.classes\n",
    "\n",
    "# 4. Diviser les données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Entraîner XGBoost pour la classification en utilisant le GPU\n",
    "xgb_model = LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Évaluer le modèle sur l'ensemble de test\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Exactitude du modèle XGBoost: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n",
      "GPU Name:  NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Vérifier si CUDA est disponible\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "\n",
    "# Si CUDA est disponible, afficher le nom de ton GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name: \", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/10], Loss: 0.5008\n",
      "Epoch [2/10], Loss: 0.1253\n",
      "Epoch [3/10], Loss: 0.1049\n",
      "Epoch [4/10], Loss: 0.0806\n",
      "Epoch [5/10], Loss: 0.0635\n",
      "Epoch [6/10], Loss: 0.0655\n",
      "Epoch [7/10], Loss: 0.0394\n",
      "Epoch [8/10], Loss: 0.0392\n",
      "Epoch [9/10], Loss: 0.0301\n",
      "Epoch [10/10], Loss: 0.0454\n",
      "Exactitude du modèle: 94.60%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, models\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Vérifier si CUDA est disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Charger le modèle pré-entraîné ResNet\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.to(device)  # Déplacer le modèle vers le GPU si disponible\n",
    "\n",
    "# Appliquer les transformations sur les images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Charger les données d'entraînement\n",
    "train_data = datasets.ImageFolder('./dataset/car_or_truck/train', transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Charger les données de test\n",
    "test_data = datasets.ImageFolder('./dataset/car_or_truck/valid', transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Critère de perte et optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.train()\n",
    "for epoch in range(10):  # 10 époques d'exemple\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Modèle en mode évaluation\n",
    "model.eval()\n",
    "\n",
    "# Initialisation des listes pour stocker les prédictions et les étiquettes réelles\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Parcourir les données de test\n",
    "with torch.no_grad():  # Désactive le calcul des gradients pendant l'évaluation\n",
    "    for inputs, labels in test_loader:\n",
    "        # Transférer les données vers le GPU si disponible\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Prédictions avec le modèle\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # La classe prédite est celle avec la probabilité la plus élevée\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Ajouter les prédictions et les étiquettes réelles à la liste\n",
    "        all_preds.extend(preds.cpu().numpy())  # Transférer sur le CPU pour l'utilisation avec numpy\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculer l'exactitude\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Exactitude du modèle: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
